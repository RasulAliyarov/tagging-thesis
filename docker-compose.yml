services:
  # AI service (FastAPI)
  nlp-worker:
    build: ./services/nlp-worker
    ports:
      - "8001:8001"
    volumes:
      - ./services/nlp-worker:/app
    networks:
      - ai-network
    env_file:
      - .env
    # Run FastAPI with auto-reload (development mode)
    command: uvicorn main:app --host 0.0.0.0 --port 8001 --reload

  # Frontend (Next.js)
  frontend:
    build: ./services/frontend
    ports:
      - "3000:3000"
    volumes:
      - ./services/frontend:/app   # Mount only the frontend folder
      - /app/node_modules          # Protect container-installed dependencies
      - /app/.next                 # Protect Next.js build cache
    environment:
      # IMPORTANT:
      # For client-side requests we keep localhost,
      # but if you use SSR, a different approach is required
      - NEXT_PUBLIC_API_URL=http://localhost:8001  # API endpoint for the frontend
      - WATCHPACK_POLLING=true                     # Enables hot reload on Windows
    networks:
      - ai-network
    depends_on:
      - nlp-worker

networks:
  # Custom bridge network for internal communication
  ai-network:
    driver: bridge
